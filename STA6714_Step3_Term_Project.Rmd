---
title: "STA6714_Step3_Term_Project"
author: "Benjamin Garcia"
date: "`r Sys.Date()`"
output: html_document
---

```{r }
library(readxl)
library(ggplot2)
features2 <- read_excel("features2.xlsx")
```


```{r }
table(features2$JJS, features2$Label)
table(features2$NNP)
table(features2$WRB)
table(features2$exclamationmarks, features2$Label)
#table(features2$questionmarks)
#table(features2$semicolon)
table(features2$ellipsis)
table(features2$TOs, features2$Label)

# can remove predictors JJS, NNP, WRB, exclamationmark, TOs, and ellipsis due to sparsity or all zeroes

```



```{r }
table(features2$sentence1st)
table(features2$sentencelast)

# can remove these as well
```

```{r}
feat3 <- features2[,-c(1, 2, 15, 19, 31, 42, 51, 60 , 61 )]

# removed TextID, URL, JJS, NNP, TOs, WRB, ellipsis, sentence1st, sentencelast 
```


```{r}
# Let 1 = objective and 0 = subjective

feat3$Label <- ifelse(feat3$Label == "objective", 1, 0)
table(feat3$Label)
```

```{r}
# looking for large correlation values

round(cor(feat3[,c(1,43:53)]), 2)

round(cor(feat3[,c(1:17)]), 2)

round(cor(feat3[,c(1,18:32)]), 2)

round(cor(feat3[,c(1,32:42)]), 2)
```

```{r}
library(reshape) 

cor.mat2 <- round(cor(feat3[,c(1:13)]), 2) 
melted.cor.mat2 <- melt(cor.mat2)
ggplot(melted.cor.mat2, aes(x=X1, y=X2, fill=value)) +
  geom_tile() + xlab("") + ylab("") + ggtitle("Heatmap for word and grammar predictors") +
  scale_fill_distiller(palette="RdBu", limits=c(-1, 1))
```

```{r}
# The following variables are being removed due to high correlation with other predictors

feat4 <- feat3[,-c(2,3,4,6,9,10,14,21,26,31,40,41,37,47,52)]
```



```{r}
#round(cor(feat4), 2) > .7

cor.mat3 <- round(cor(feat4[,]), 2) 
melted.cor.mat3 <- melt(cor.mat3)
ggplot(melted.cor.mat3, aes(x=X1, y=X2, fill=value)) +
  geom_tile() + xlab("") + ylab("") + ggtitle("Heatmap for word and grammar predictors") +
  scale_fill_distiller(palette="RdBu", limits=c(-1, 1))
```

```{r}
#additional removal due to correlation

feat5 <- feat4[,-c(5,7,9,12,13,17,18,19,20,21,22,29,34,36,37)]
```


```{r}
cor.mat4 <- round(cor(feat5[,]), 2) 
melted.cor.mat4 <- melt(cor.mat4)
ggplot(melted.cor.mat4, aes(x=X1, y=X2, fill=value)) +
  geom_tile() + xlab("") + ylab("") + ggtitle("Heatmap for word and grammar predictors") +
  scale_fill_distiller(palette="RdBu", limits=c(-1, 1))
```

```{r}
# exploratory data analysis

barplot(tapply(feat5$pronouns1st, feat5$Label, median), xlab = "Label",
        ylab = "Median first person pronouns", main = "Barplot of median first person pronouns for
      objective vs subjective", col = c("red", "blue"))
```

```{r}
g <- hist(feat5$Quotes, main = "Histogram of number of quotes used", 
          xlab = "Quotes", col = "brown")
text(g$mids,g$counts,labels=g$counts, adj=c(0.5, -0.5))

table(feat5$Quotes)
```

```{r}
ggplot(feat5, aes(as.factor(Label), txtcomplexity)) + geom_boxplot() + 
  labs(title = "Boxplots of text complexity by objective vs
        subjective", x = "Label") 
```

```{r}
ggplot(feat5, aes(x = NN, y = RB, color = as.factor(Label))) + geom_point() + 
  labs(title = "Frequency of Singular Nouns Against Adverb Colored by Target",
       x = "Singular Nouns", y = "Adverb")
```

```{r}
# scaling

feat5_scal <- cbind(feat5[,1], scale(feat5[,c(2:23)]))
```


```{r}
# full model
set.seed(7)

ind <- sample(1:1000, 700, replace = F)
train.df <- feat5_scal[ind,]
holdout.df <- feat5_scal[-ind,]

logmod1 <- glm(formula = Label ~., family = binomial(link = "logit"), data = train.df)

summary(logmod1)

```

```{r}
# Step-wise or bidirection regression applied to full model

step_mod_both <- MASS::stepAIC(
  object = logmod1,
  direction = "both"
)

step_mod_both
```

```{r}
summary(step_mod_both)
```


```{r}
anova(logmod1, step_mod_both, test = "Chisq")
```

```{r}
pred <- predict(step_mod_both, holdout.df[,2:23])

prob.predictions <- 1 / (1 + exp(-pred))
```


```{r}
# confusion matrix for .5

caret::confusionMatrix(factor(ifelse(prob.predictions > .5, 1, 0)), factor(holdout.df$Label))

```

```{r}
# ROC curve
library(ROCR)
predob <- prediction(ifelse(prob.predictions > .5, 1, 0), holdout.df$Label)
perf <- performance(predob, "tpr", "fpr")
perf.df <- data.frame(tpr = perf@x.values[[1]],
                      fpr = perf@y.values[[1]])
ggplot2::ggplot(perf.df, aes(x = tpr, y = fpr))+
  geom_line()+
  geom_segment(aes(x=0, y=0, xend=1, yend=1), color = "gray", linetype = "dashed")+
  labs(x = "1-Specificity", y = "Sensitivity")

performance(predob, measure = "auc")@y.values[[1]]

```

```{r}
coef(step_mod_both)
```

```{r}
library(rpart)
library(rpart.plot)

dtree <- rpart(Label ~ EX + JJR + PDT + RB + WDT + WP + `WP$` + 
    Quotes + questionmarks + past, data = train.df, method = "class")
```

```{r}
rpart.plot(dtree, extra = 1)
```

```{r}
# pruned tree

dtree_p <- rpart(Label ~ EX + JJR + PDT + RB + WDT + WP + `WP$` + 
    Quotes + questionmarks + past, data = train.df, method = "class",
    cp = .00001, minsplit = 5, xval = 5)

printcp(dtree_p)

# based on the table the tree with 4 splits and had the lowest cross validation error of
# 0.49225 and cp of 0.0129199
```

```{r}
# pruned tree with cp with lowest xerror
pruneddt <- prune(dtree_p,
                  cp = .0129199)
sum(dtree_p$frame$var == "<leaf>")
rpart.plot(pruneddt, extra = 1, fallen.leaves = F)
```

```{r}
# prediction and confusion matrix for training

pdt_predict_train <- predict(pruneddt, type = "class")
caret::confusionMatrix(as.factor(pdt_predict_train), as.factor(train.df$Label))

# about .825 accuracy
```

```{r}
# prediction and confusion matrix for holdout

pdt_predict_holdout <- predict(pruneddt, holdout.df, type = "class")
caret::confusionMatrix(as.factor(pdt_predict_holdout), as.factor(holdout.df$Label))

# For the holdout data the accuracy is about .78
```

```{r}
train2 <- train.df
train2$WPS <- train2$`WP$`

holdout2 <- holdout.df
holdout2$WPS <- holdout2$`WP$`
```


```{r}

library(randomForest)
rand_for <- randomForest(Label ~ EX + JJR + PDT + RB + WDT + WP + WPS + 
   Quotes + questionmarks + past, data = train2, ntree = 500, mtry = 4, nodesize = 5, importance = T )

```

```{r}
varImpPlot(rand_for, type = 1)

```



```{r}
# confusion matrix

rf.pred <- predict(rand_for, holdout2, type = "class")
caret::confusionMatrix(as.factor(ifelse(rf.pred > .5, 1, 0)), as.factor(holdout2$Label))

```

```{r}
# Boosting

library(xgboost)

xbg <- caret::train(factor(Label) ~ EX + JJR + PDT + RB + WDT + WP + `WP$` + 
    Quotes + questionmarks + past, data = train.df, method = "xgbTree", verbosity = 0)



```


```{r}
library(ROCR)

rocCD <- function(model, data) {
  prob_bt <- predict(model, data)
  predob_bt <- prediction(prob_bt, data$Label)
  perf_bt <- performance(predob_bt, "tpr", "fpr")
  return(data.frame(tpr = perf_bt@x.values[[1]], fpr = perf_bt@y.values[[1]]))
}

performance_df <- rbind(
  cbind(rocCD(xbg, holdout.df), model = "xgboost")
)
```

```{r}
# boosting matrix

boosting.pred <- predict(xbg, holdout2)

caret::confusionMatrix(as.factor(boosting.pred), as.factor(holdout2$Label))

```



```{r}
# bagging and matrix
#install.packages("adabag")
bagged <- caret::train(factor(Label) ~ EX + JJR + PDT + RB + WDT + WP + `WP$` + 
    Quotes + questionmarks + past, data = train.df, method = "rf", verbosity = 0)

bagging.pred <- predict(bagged, holdout2)

caret::confusionMatrix(as.factor(bagging.pred), as.factor(holdout2$Label))
```



```{r}
colly <- c("xgboost" = "tomato")
library(ggplot2)
ggplot(performance_df, aes(x = tpr, y = fpr, color = model))+
  geom_line() +
  scale_color_manual(values = colly) +
  geom_segment(aes(x = 0, y = 0, xend = 1, yend = 1), color = "gray", linetype = "dashed")+
  labs(x = "1 - specificity", y = "Sensitivity", color = "Model")
```


```{r}
performance(prediction(predict(xbg, holdout.df), holdout.df$Label), measure = "auc")@y.values[[1]]
```
```{r}
# naive bayes

library(tidyverse)
library(caret)
library(e1071)

obj_nb <- naiveBayes(factor(Label) ~ factor(EX) + factor(JJR) + factor(PDT) + factor(RB) + factor(WDT) + factor(WP) + factor(WPS) + factor(Quotes) + factor(questionmarks) + factor(past), data = train2)

obj_nb
```

```{r}
prop.table(table(train2$Label, train2$Quotes), margin = 1)
```

```{r}

holdout2$Label <- factor(holdout2$Label)
holdout2$EX <- factor(holdout2$EX)
holdout2$JJR <- factor(holdout2$JJR)
holdout2$PDT <- factor(holdout2$PDT)
holdout2$RB <- factor(holdout2$RB)
holdout2$WDT <- factor(holdout2$WDT)
holdout2$WP <- factor(holdout2$WP)
holdout2$WPS <- factor(holdout2$WPS)
holdout2$Quotes <- factor(holdout2$Quotes)
holdout2$questionmarks <- factor(holdout2$questionmarks)
holdout2$past <- factor(holdout2$past)

nb_pp <- predict(obj_nb, newdata = holdout2, type = "raw")
nb_pred_class <- predict(obj_nb, newdata = holdout2)

df_nb <- data.frame(actual = holdout2$Label, prediced = nb_pred_class, nb_pp)


```



```{r}
confusionMatrix(factor(predict(obj_nb, newdata = train2)), factor(train2$Label))


```

```{r}
#confusionMatrix(as.factor(ifelse(nb_pp[] > .5, 1, 0)), as.factor(holdout2$Label))
```

```{r}
train2$bin_qm <- cut(as.numeric(train2$questionmarks), breaks=3)
train2$bin_quot <- cut(as.numeric(train2$Quotes), breaks=3)
train2$bin_wps <- cut(as.numeric(train2$WPS), breaks=3)

holdout2$bin_qm <- cut(as.numeric(holdout2$questionmarks), breaks=3)
holdout2$bin_quot <- cut(as.numeric(holdout2$Quotes), breaks=3)
holdout2$bin_wps <- cut(as.numeric(holdout2$WPS), breaks=3)

library(tidyverse)
library(caret)
library(e1071)

obj_nb <- naiveBayes(factor(Label) ~ factor(bin_qm) + factor(bin_quot) + factor(bin_wps) , data = train2)

obj_nb

nb_pred_class <- predict(obj_nb, newdata = holdout2)

confusionMatrix(as.factor(nb_pred_class), as.factor(holdout2$Label))

```

